{"cells":[{"cell_type":"markdown","source":["# Mount from dive"],"metadata":{"id":"e-CNds7Yci-r"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"P5255iN4coK2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Install dependecies"],"metadata":{"id":"zxcwYw5Yc6i9"}},{"cell_type":"code","source":["! pip install transformers"],"metadata":{"id":"3ui9n2waec8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install Arabic-Stopwords"],"metadata":{"id":"qtprlLuFc_qk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install python-terrier"],"metadata":{"id":"HQrQDfiGe_1v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import libraries"],"metadata":{"id":"kL85KxjHfJ7v"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNq9BFs-XD_w"},"outputs":[],"source":["import re\n","import pandas as pd\n","from snowballstemmer import stemmer\n","import arabicstopwords.arabicstopwords as ar_stp\n","import pyterrier as pt\n","# pyterrier is a Python API for Terrier. Link: https://github.com/terrier-org/pyterrier\n","# Terrier IR Platform is a modular open source software for the rapid development of large-scale information retrieval applications.\n","if not pt.started():\n","   pt.init(helper_version=\"0.0.6\")\n","import os\n","from transformers import pipeline\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","import time\n","import uuid"]},{"cell_type":"markdown","source":["# Define important constant"],"metadata":{"id":"j4KEesbWlYC9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vu6p6JiXD_2"},"outputs":[],"source":["# define some global constants\n","TEXT = \"text\"\n","QUERY = \"query\"\n","LABEL = \"label\"\n","RANK = \"rank\"\n","TAG = \"tag\"\n","SCORE = \"score\"\n","QID = \"qid\"\n","DOC_NO = \"docno\"\n","DOCID = \"docid\""]},{"cell_type":"markdown","metadata":{"id":"bU8rwQL_XD_9"},"source":["### Preprocessing\n","Preprocess the arabic input text by performing normalization, stemming, and removing stop words."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TvxK0N6GXD_-"},"outputs":[],"source":["# Clean text from urls, handles, special characters, tabs, line jumps, and extra white space.\n","def clean(text):\n","    text = re.sub(r\"http\\S+\", \" \", text)  # remove urls\n","    text = re.sub(r\"@[\\w]*\", \" \", text)  # remove handles\n","    text = re.sub(r\"[\\.\\,\\#_\\|\\:\\?\\?\\/\\=]\", \" \", text) # remove special characters\n","    text = re.sub(r\"\\t\", \" \", text)  # remove tabs\n","    text = re.sub(r\"\\n\", \" \", text)  # remove line jump\n","    text = re.sub(r\"\\s+\", \" \", text)  # remove extra white space\n","    text = re.sub(r'[^\\w\\s]', '', text) # Removing punctuations in string using regex\n","    text = text.strip()\n","    return text\n","\n","# arabic stemmer\n","ar_stemmer = stemmer(\"arabic\")\n","# remove arabic stop words\n","def ar_remove_stop_words(sentence):\n","    terms=[]\n","    stopWords= set(ar_stp.stopwords_list())\n","    for term in sentence.split() :\n","        if term not in stopWords :\n","            terms.append(term)\n","    return \" \".join(terms)\n","\n","\n","# normalize the arabic text\n","def normalize_arabic(text):\n","    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n","    text = re.sub(\"ى\", \"ي\", text)\n","    text = re.sub(\"ؤ\", \"ء\", text)\n","    text = re.sub(\"ئ\", \"ء\", text)\n","    text = re.sub(\"ة\", \"ه\", text)\n","    return(text)\n","\n","# stem the arabic text\n","def ar_stem(sentence):\n","    return \" \".join([ar_stemmer.stemWord(i) for i in sentence.split()])\n","\n","\n","# apply all preprocessing steps needed for Arabic text\n","def preprocess_arabic(text):\n","    text = normalize_arabic(text)\n","    text = ar_remove_stop_words(text)\n","    text = ar_stem(text)\n","    return text\n","\n","\n","def prepare_query_for_search(query):\n","        print(\"Cleaning queries and applying preprocessing steps\")\n","        id = uuid.uuid4()\n","        processed_query = preprocess_arabic(query)\n","        processed_id = str(id) # convert the id column to string\n","        df_query = pd.DataFrame(data={QUERY:[processed_query], QID:[processed_id]},columns=[QUERY, QID])\n","        print(\"Done with preparation!\")\n","        return df_query\n"]},{"cell_type":"markdown","source":["# Create index for search"],"metadata":{"id":"3HsT_-vMHFF2"}},{"cell_type":"code","source":["train = pd.read_csv(\"/content/drive/MyDrive/Quran_QA/DataCsv/train.csv\")\n","validation = pd.read_csv(\"/content/drive/MyDrive/Quran_QA/DataCsv/validation.csv\")"],"metadata":{"id":"GUBSQ-c8lBoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_data = pd.concat([train, validation])\n","all_data = all_data[[\"pq_id\", \"passage\"]]\n","all_data = all_data.drop_duplicates()\n","all_data[\"passage\"] = all_data[\"passage\"].apply(preprocess_arabic)\n","df = all_data.rename(columns={\"pq_id\":\"docno\",\"passage\":\"text\"})"],"metadata":{"id":"YmUZbnuemd51"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.options.display.max_rows = None\n","pd.options.display.max_colwidth = None"],"metadata":{"id":"bbeo8E7Ha7RA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# index the text, record the docnos as metadata\n","# pd_indexer = pt.DFIndexer(\"/content/drive/MyDrive/Quran_QA/QPC_Index\")\n","# pd_indexer.setProperty(\"tokeniser\", \"UTFTokeniser\")\n","# indexref = pd_indexer.index(df[\"text\"], df[\"docno\"])"],"metadata":{"id":"YMmDpV-dH4Q1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LiFHvbOYXD_7"},"source":["## Search in the index\n","\n","Before searching in the index, we need to prepare some functions to clean the input text."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHkhwOCkXD_5"},"outputs":[],"source":["def load_index(index_path):\n","    try:\n","        index = pt.IndexFactory.of(index_path)\n","        print(\"Index was loaded successfully from this path: \", index_path)\n","        return index\n","    except Exception as e:\n","        print('Cannot load the index, check exception details {}'.format(e))\n","        return []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UIpc4NIKXD_6"},"outputs":[],"source":["index_path = \"/content/drive/MyDrive/Quran_QA/QPC_Index/data.properties\"\n","\n","index = load_index(index_path=index_path)"]},{"cell_type":"markdown","metadata":{"id":"HcElOfzwXD__"},"source":["## Search\n","Search in the index and find the relevant passages."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SfNmcBBUXD__"},"outputs":[],"source":["# 1. initialize the BM25 retrieval model\n","BM25_model = pt.BatchRetrieve(index, wmodel=pipe, metadata=[\"docno\"],num_results=5)\n","\n","# 2. read the query file and prepare it for search to match pyterrier format\n","df_query = prepare_query_for_search(query)\n","\n","# 3. search using BM25 model\n","df_run = BM25_model.transform(df_query)\n","\n","# 4. save the run in trec format to a file\n","df_run[\"Q0\"] = [\"Q0\"] * len(df_run)\n","df_run[\"tag\"] = [\"BM25\"] * len(df_run)\n","df_run"]},{"cell_type":"markdown","source":["# Prepare data to get final context"],"metadata":{"id":"JRDePC_7lxie"}},{"cell_type":"code","source":["train.iloc[30][\"passage\"]"],"metadata":{"id":"-zl11cNreExI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["retrivd_passage = list(df_run[\"docno\"].values)"],"metadata":{"id":"NCGdE2-FnMR9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["retrivd_passage"],"metadata":{"id":"Ag4y-lnkChjG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train[train[\"pq_id\"].isin(retrivd_passage)]"],"metadata":{"id":"P0Wfei0foifk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context = train[train[\"pq_id\"]==\"6:91-92_407\"][\"passage\"].values[0]"],"metadata":{"id":"zqKWl4TLqxo7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context"],"metadata":{"id":"T52EdjeffH-_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def answer_question(message):\n","    pipe = pipeline(\"question-answering\", model=\"hemagamal/mdeberta_Quran_qa\", tokenizer=\"hemagamal/mdeberta_Quran_qa\")\n","    result_row = pipe(question=message,context=context,handle_impossible_answer=True, topk=1)\n","    return result_row[\"answer\"]"],"metadata":{"id":"fx233ld9o3kR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["answer_question(query)"],"metadata":{"id":"9cTHFMuI9XFQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["query"],"metadata":{"id":"3ml76st3ERge"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"tweetEnv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}